name: Rust CI/CD

on:
  push:
    branches: ["main"]
    tags:
      - "v*"
  pull_request:

env:
  CARGO_TERM_COLOR: always

defaults:
  run:
    shell: bash

jobs:
  lint:
    name: Lint
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Environment
        uses: ./.github/actions/setup-daq
        with:
          components: rustfmt, clippy

      - name: Install SARIF tools
        run: cargo install clippy-sarif sarif-fmt

      - name: cargo fmt --check
        run: cargo fmt --all --check

      - name: cargo clippy
        run: cargo clippy --workspace --all-targets --all-features -- -D warnings

      - name: cargo clippy (SARIF)
        run: |
          cargo clippy --workspace --all-targets --all-features --message-format=json -- -D warnings | \
          clippy-sarif | tee clippy-results.sarif | sarif-fmt
        continue-on-error: true

      - name: Upload SARIF results to GitHub Security
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: clippy-results.sarif
          wait-for-processing: true
        if: always()

  ast-grep:
    name: AST-Grep Quality Checks
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Install ast-grep
        run: |
          curl -L https://github.com/ast-grep/ast-grep/releases/latest/download/ast-grep-x86_64-unknown-linux-gnu.zip -o ast-grep.zip
          unzip ast-grep.zip
          chmod +x ast-grep
          sudo mv ast-grep /usr/local/bin/

      - name: Run ast-grep scan
        id: ast-grep-scan
        run: |
          # Run ast-grep and capture JSON output
          ast-grep scan --config rust_daq_ast_grep_rules.yml --json > ast-grep-results.json || true
          
          # Check for ERROR severity violations
          ERROR_COUNT=$(jq '[.[] | select(.severity == "error")] | length' ast-grep-results.json)
          WARNING_COUNT=$(jq '[.[] | select(.severity == "warning")] | length' ast-grep-results.json)
          HINT_COUNT=$(jq '[.[] | select(.severity == "hint")] | length' ast-grep-results.json)
          
          echo "error_count=$ERROR_COUNT" >> $GITHUB_OUTPUT
          echo "warning_count=$WARNING_COUNT" >> $GITHUB_OUTPUT
          echo "hint_count=$HINT_COUNT" >> $GITHUB_OUTPUT
          
          # Display summary
          echo "### AST-Grep Results"
          echo "- Errors: $ERROR_COUNT"
          echo "- Warnings: $WARNING_COUNT"
          echo "- Hints: $HINT_COUNT"
          
          # Show detailed results if any violations found
          if [ "$ERROR_COUNT" -gt 0 ] || [ "$WARNING_COUNT" -gt 0 ] || [ "$HINT_COUNT" -gt 0 ]; then
            echo ""
            echo "Detailed violations:"
            jq -r '.[] | "[\(.severity | ascii_upcase)] \(.file):\(.range.start.line) - \(.message)"' ast-grep-results.json
          fi

      - name: Upload ast-grep results artifact
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: ast-grep-results-${{ github.sha }}
          path: ast-grep-results.json
          if-no-files-found: error

      - name: Fail on ERROR violations
        if: steps.ast-grep-scan.outputs.error_count > 0
        run: |
          echo "::error::Found ${{ steps.ast-grep-scan.outputs.error_count }} ERROR severity violations"
          echo "Please fix the ERROR violations before merging."
          exit 1

      - name: Comment on warnings
        if: steps.ast-grep-scan.outputs.warning_count > 0 || steps.ast-grep-scan.outputs.hint_count > 0
        run: |
          echo "::warning::Found ${{ steps.ast-grep-scan.outputs.warning_count }} warnings and ${{ steps.ast-grep-scan.outputs.hint_count }} hints"
          echo "These are informational and do not block the build."

  security:
    name: Security Audit
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Environment
        uses: ./.github/actions/setup-daq

      - name: Run cargo-audit
        uses: rustsec/audit-check@v1.4.1
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

  docs:
    name: Documentation
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Environment
        uses: ./.github/actions/setup-daq

      - name: Check documentation builds
        run: cargo doc --workspace --all-features --no-deps --document-private-items
        env:
          RUSTDOCFLAGS: -D warnings

      - name: Upload documentation artifact
        uses: actions/upload-artifact@v4
        with:
          name: docs-${{ github.sha }}
          path: target/doc
          if-no-files-found: error

  blueprints:
    name: Rerun Blueprints
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Regenerate blueprints
        run: scripts/regenerate_blueprints.sh

      - name: Upload blueprints artifact
        uses: actions/upload-artifact@v4
        with:
          name: rerun-blueprints-${{ github.sha }}
          path: |
            crates/daq-server/blueprints/*.rbl
          if-no-files-found: error

  tee-bench:
    name: Tee Bench Sample
    runs-on: ubuntu-latest
    needs: [lint, ast-grep]
    if: github.event_name != 'pull_request' || contains(github.event.pull_request.labels.*.name, 'tee-bench')
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Environment
        uses: ./.github/actions/setup-daq

      - name: Run tee bench (sample)
        env:
          TEE_BENCH_LATENCY: 1
        run: |
          set -e
          {
            echo "=== Tee bench: 50k msgs, payload 0 ==="
            TEE_BENCH_MESSAGES=50000 TEE_BENCH_PAYLOAD=0 cargo run -p daq-core --example tee_bench --release
            echo
            echo "=== Tee bench: 50k msgs, payload 256 ==="
            TEE_BENCH_MESSAGES=50000 TEE_BENCH_PAYLOAD=256 cargo run -p daq-core --example tee_bench --release
            echo
            echo "=== Tee bench: 20k msgs, payload 256, buffer 32 (backpressure) ==="
            TEE_BENCH_MESSAGES=20000 TEE_BENCH_PAYLOAD=256 TEE_BENCH_BUFFER=32 cargo run -p daq-core --example tee_bench --release
          } | tee tee_bench_output.txt

      - name: Upload bench output
        uses: actions/upload-artifact@v4
        with:
          name: tee-bench-${{ github.sha }}
          path: tee_bench_output.txt
          if-no-files-found: error

  test:
    name: Tests (${{ matrix.os }})
    runs-on: ${{ matrix.os }}
    needs: [lint, ast-grep]
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, macos-latest, windows-latest]
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Environment
        uses: ./.github/actions/setup-daq

      - name: Unit and integration tests
        run: cargo test --workspace --all-targets

      - name: Documentation tests
        run: cargo test --workspace --doc

  hardware-tests:
    name: Hardware Tests (Tailnet)
    runs-on: ubuntu-latest
    needs: [lint, ast-grep]
    # Only run on main branch to avoid burning through Tailscale auth keys on every PR
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Environment
        uses: ./.github/actions/setup-daq

      - name: Connect to Tailscale
        uses: tailscale/github-action@v2
        with:
          authkey: ${{ secrets.TAILSCALE_AUTHKEY }}

      - name: Test SSH access and serial ports
        env:
          SSH_HOST: ${{ secrets.MAITAI_SSH_HOST }}
          SSH_USER: ${{ secrets.MAITAI_SSH_USER }}
        run: |
          echo "Testing SSH access to $SSH_HOST..."
          ssh -o StrictHostKeyChecking=no $SSH_USER@$SSH_HOST '
            echo "SSH connection successful."
            echo "Verifying serial ports..."
            ls -l /dev/ttyUSB* /dev/ttyS*
          '

      - name: Run PVCAM smoke test
        env:
          SSH_HOST: ${{ secrets.MAITAI_SSH_HOST }}
          SSH_USER: ${{ secrets.MAITAI_SSH_USER }}
        run: |
          echo "Running PVCAM hardware smoke test on remote..."
          ssh -o StrictHostKeyChecking=no $SSH_USER@$SSH_HOST '
            source /opt/pvcam/etc/profile.d/pvcam.sh 2>/dev/null || true
            export PVCAM_SDK_DIR=/opt/pvcam/sdk
            export LD_LIBRARY_PATH=/opt/pvcam/library/x86_64:$LD_LIBRARY_PATH
            export LIBRARY_PATH=/opt/pvcam/library/x86_64:$LIBRARY_PATH
            export PVCAM_SMOKE_TEST=1
            export PVCAM_CAMERA_NAME=PrimeBSI
            cd ~/rust-daq-sync || cd ~/rust-daq
            cargo test --test pvcam_hardware_smoke \
              --features "instrument_photometrics,pvcam_hardware" \
              -- --nocapture
          '
        continue-on-error: true

      - name: Run hardware integration tests (when available)
        run: |
          echo "Additional hardware tests can be added here"
          echo "Example: cargo test --test hardware_integration -- --ignored"
        continue-on-error: true

  features:
    name: Feature Builds (${{ matrix.feature-set }})
    runs-on: ubuntu-latest
    needs: lint
    strategy:
      fail-fast: false
      matrix:
        include:
          - feature-set: default
            args: ""
          - feature-set: full
            args: "--features full"
          - feature-set: storage_csv
            args: "--no-default-features --features storage_csv"
          - feature-set: storage_hdf5
            args: "--no-default-features --features storage_hdf5"
          - feature-set: storage_arrow
            args: "--no-default-features --features storage_arrow"
          - feature-set: instrument_serial
            args: "--no-default-features --features instrument_serial"
          - feature-set: instrument_visa
            args: "--no-default-features --features instrument_visa"
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Environment
        uses: ./.github/actions/setup-daq
        with:
          cache-key: feature-builds

      - name: cargo build ${{ matrix.feature-set }}
        run: |
          cargo build --workspace ${{ matrix.args }}

  coverage:
    name: Coverage
    runs-on: ubuntu-latest
    needs: [test, features, security, docs]
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Environment
        uses: ./.github/actions/setup-daq
        with:
          components: llvm-tools-preview
          cache-key: coverage

      - name: Install cargo-llvm-cov
        uses: taiki-e/install-action@v2
        with:
          tool: cargo-llvm-cov

      - name: Generate coverage report
        run: |
          mkdir -p coverage
          cargo llvm-cov --workspace --all-features --lcov --output-path coverage/lcov.info --html --output-dir coverage/html

      - name: Upload coverage artifact
        uses: actions/upload-artifact@v4
        with:
          name: coverage-${{ github.sha }}
          path: coverage
          if-no-files-found: error

  release:
    name: Release (${{ matrix.os }})
    if: startsWith(github.ref, 'refs/tags/')
    needs: [lint, test, features, coverage]
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-latest, macos-latest, windows-latest]
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Environment
        uses: ./.github/actions/setup-daq
        with:
          cache-key: release-${{ matrix.os }}

      - name: Build release binaries
        run: cargo build --workspace --features full --release

      - name: Package artifacts
        run: |
          ARTIFACT_DIR="artifacts"
          ARTIFACT_NAME="rust-daq-${{ matrix.os }}-${{ github.ref_name }}"
          mkdir -p "$ARTIFACT_DIR"
          if [[ "${{ runner.os }}" == "Windows" ]]; then
            cp target/release/rust-daq-daemon.exe "$ARTIFACT_DIR/"
            cp target/release/rust-daq-gui.exe "$ARTIFACT_DIR/"
            pwsh -Command "Compress-Archive -Path '${ARTIFACT_DIR}/*.exe' -DestinationPath '${ARTIFACT_DIR}/${ARTIFACT_NAME}.zip' -Force"
            rm "$ARTIFACT_DIR"/*.exe
          else
            cp target/release/rust-daq-daemon "$ARTIFACT_DIR/"
            cp target/release/rust-daq-gui "$ARTIFACT_DIR/"
            tar -czf "$ARTIFACT_DIR/${ARTIFACT_NAME}.tar.gz" -C "$ARTIFACT_DIR" rust-daq-daemon rust-daq-gui
            rm "$ARTIFACT_DIR"/rust-daq-daemon "$ARTIFACT_DIR"/rust-daq-gui
          fi

      - name: Upload release artifact
        uses: actions/upload-artifact@v4
        with:
          name: ${{ matrix.os }}-release-${{ github.ref_name }}
          path: artifacts
          if-no-files-found: error

  publish-release:
    name: Publish Release
    if: startsWith(github.ref, 'refs/tags/')
    needs: release
    runs-on: ubuntu-latest
    steps:
      - name: Download artifacts
        uses: actions/download-artifact@v4
        with:
          path: release-artifacts

      - name: Create GitHub Release
        uses: softprops/action-gh-release@v1
        with:
          files: release-artifacts/**/*
          generate_release_notes: true
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

  sync-public:
    name: Sync to Public Repository
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    needs: [lint, test, features, security, docs, coverage]
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Push to public repository
        run: |
          git remote add public https://x-access-token:${{ secrets.PUBLIC_REPO_TOKEN }}@github.com/easternanemone/rust-daq.git
          git push public main --tags --force
        env:
          GIT_AUTHOR_NAME: ${{ github.event.head_commit.author.name }}
          GIT_AUTHOR_EMAIL: ${{ github.event.head_commit.author.email }}
          GIT_COMMITTER_NAME: ${{ github.event.head_commit.committer.name }}
          GIT_COMMITTER_EMAIL: ${{ github.event.head_commit.committer.email }}
